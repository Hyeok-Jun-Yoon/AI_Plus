{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 소비 패턴 기반 패션 추천 LLM 서비스"
      ],
      "metadata": {
        "id": "tEAuMvmHVJOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   기술 스텍 및 모델 선정\n",
        "\n",
        "\n",
        "*   입력 처리 모듈\n",
        "*   모델 처리 모듈(MLLM)\n",
        "*   추천 생성 모듈\n",
        "\n",
        "> 이미지 및 언어 모델 : CLIP / GPT\n",
        "\n",
        "> 추천 알고리 : Cosine Similarity, k-Nearest Neighbor (k-NN), Ranking Algorithms\n",
        "\n",
        "\n",
        "2.   아키텍처 설계\n",
        "*    입력단계 : 이미지 업로드 / 텍스트 입력 (구매한 물품들의 특징에 대한 설명(브랜드,스타일,색상)\n",
        "*    추천 prompt 생성 : 이미지임베딩과 텍스트 임베딩을 결합하여 추천 prompt 생성\n",
        "\n",
        "\n",
        "> ex) 구매한 물품 이미지들 (예: \"청바지, 블라우스, 운동화\")\n",
        "텍스트 프롬프트 (예: \"운동복을 좋아하는 30대 남성 고객에게 어울리는 패션 아이템을 추천해 주세요\")\n",
        "\n",
        "*    출력 단계 : 추천된 패션 아이템 목록을 이미지 및 텍스트 형태 출력\n",
        "\n",
        "3. 서비스 개발 흐름\n",
        "\n",
        "\n",
        ">1. 사용자가 전신 이미지와 구매한 아이템 이미지를 업로드.\n",
        "2. CLIP 모델로 각 이미지를 임베딩 벡터로 변환.\n",
        "3. GPT 모델로 패션 아이템 추천 텍스트 생성.\n",
        "4. 추천된 패션 아이템 이미지 임베딩을 CLIP 모델로 추출.\n",
        "5. 사용자 이미지와 추천된 아이템 이미지 간의 유사도 계산.\n",
        "6. 가장 유사한 아이템을 추천하고, 텍스트 설명을 함께 제공.\n",
        "\n",
        "\n",
        "4. 생각해보기\n",
        "\n",
        "\n",
        "> 나중에 라벨링을 어떻게 할지 고민해봐야.?\n",
        "\n",
        "> 화장품 추천해주는 것도 좋다고 멘토링시간에 얘기해주심\n",
        "  * 얼굴 관련 기존 데이터셋이 많음\n",
        "\n",
        "> 외국어 학습 도우미, 맞춤형 여행지 및 맛집 추천, 역사적 사건 시뮬레이터?"
      ],
      "metadata": {
        "id": "eQSHSRaFVQBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [MYCODE] OpenAI 사전준비"
      ],
      "metadata": {
        "id": "p5llm5WhdeKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사용 라이브러리"
      ],
      "metadata": {
        "id": "YwugXCL5dnF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers torch torchvision openai pillow numpy scikit-learn fastapi uvicorn matplotlib boto3 sentence-transformers faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn4IxPdXeMrr",
        "outputId": "5ab01a38-8495-4316-913b-14b8dba9e67c",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.36.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Collecting botocore<1.37.0,>=1.36.0 (from boto3)\n",
            "  Downloading botocore-1.36.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3)\n",
            "  Downloading s3transfer-0.11.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.37.0,>=1.36.0->boto3) (2.2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.36.0-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.36.0-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu, uvicorn, jmespath, starlette, botocore, s3transfer, fastapi, boto3\n",
            "Successfully installed boto3-1.36.0 botocore-1.36.0 faiss-gpu-1.7.2 fastapi-0.115.6 jmespath-1.0.1 s3transfer-0.11.0 starlette-0.41.3 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('api_key')\n",
        "\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "AZ7vwOOPnIFf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [MYCODE] Model load"
      ],
      "metadata": {
        "id": "JKzAbn6ae18V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import openai\n",
        "\n",
        "# CLIP 로드\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\") #이미지와 텍스트 데이터 전처리\n",
        "\n",
        "# GPT-4 API 호출\n",
        "def generate_recommendation(prompt):\n",
        "  messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"system\", \"content\": \"You are an excellent stylist.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt+\"\\n## 한글로 답변해주세요\"}\n",
        "]\n",
        "  response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=messages\n",
        "    ) #response['choices'][0]['message']['content']\n",
        "  return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "MzgZzPdYn1Yo",
        "collapsed": true
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "clip_model 주요 반환 값\n",
        "\n",
        "* image_embeds : 이미지가 고유하게 나타내는 의미를 벡터로 표현한 값\n",
        "\n",
        "* text_embeds : 텍스트의 의미를 고유한 벡터 표현으로 변환한 값\n",
        "\n",
        "* logits_per_image : 입력 이미지와 텍스트 간 유사성 점수\n",
        "\n",
        "* logits_per_text : 입력 텍스트와 이미지 간 유사성 점수"
      ],
      "metadata": {
        "id": "7EE_7BoYQHLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clip_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZqLBlDN7O-qj",
        "outputId": "cfd4257e-ac13-44f6-f735-7b29da61b2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLIPModel(\n",
              "  (text_model): CLIPTextTransformer(\n",
              "    (embeddings): CLIPTextEmbeddings(\n",
              "      (token_embedding): Embedding(49408, 512)\n",
              "      (position_embedding): Embedding(77, 512)\n",
              "    )\n",
              "    (encoder): CLIPEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x CLIPEncoderLayer(\n",
              "          (self_attn): CLIPSdpaAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): CLIPMLP(\n",
              "            (activation_fn): QuickGELUActivation()\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (vision_model): CLIPVisionTransformer(\n",
              "    (embeddings): CLIPVisionEmbeddings(\n",
              "      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
              "      (position_embedding): Embedding(50, 768)\n",
              "    )\n",
              "    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (encoder): CLIPEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x CLIPEncoderLayer(\n",
              "          (self_attn): CLIPSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): CLIPMLP(\n",
              "            (activation_fn): QuickGELUActivation()\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
              "  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "clip_processor 주요 반환 값\n",
        "\n",
        "*   input_ids: 텍스트의 토큰 ID.\n",
        "*   attention_mask: 텍스트의 유효 토큰 위치를 나타내는 마스크.\n",
        "*   pixel_values: 전처리된 이미지 텐서."
      ],
      "metadata": {
        "id": "ds0PgM-7PrSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clip_processor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6wiLdiPUPKqQ",
        "outputId": "1c96eed4-3f27-4814-8651-099113d31682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLIPProcessor:\n",
              "- image_processor: CLIPImageProcessor {\n",
              "  \"crop_size\": {\n",
              "    \"height\": 224,\n",
              "    \"width\": 224\n",
              "  },\n",
              "  \"do_center_crop\": true,\n",
              "  \"do_convert_rgb\": true,\n",
              "  \"do_normalize\": true,\n",
              "  \"do_rescale\": true,\n",
              "  \"do_resize\": true,\n",
              "  \"image_mean\": [\n",
              "    0.48145466,\n",
              "    0.4578275,\n",
              "    0.40821073\n",
              "  ],\n",
              "  \"image_processor_type\": \"CLIPImageProcessor\",\n",
              "  \"image_std\": [\n",
              "    0.26862954,\n",
              "    0.26130258,\n",
              "    0.27577711\n",
              "  ],\n",
              "  \"resample\": 3,\n",
              "  \"rescale_factor\": 0.00392156862745098,\n",
              "  \"size\": {\n",
              "    \"shortest_edge\": 224\n",
              "  }\n",
              "}\n",
              "\n",
              "- tokenizer: CLIPTokenizerFast(name_or_path='openai/clip-vit-base-patch32', vocab_size=49408, model_max_length=77, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|startoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
              "\t49406: AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "\t49407: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}\n",
              ")\n",
              "\n",
              "{\n",
              "  \"processor_class\": \"CLIPProcessor\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [MYCODE] 사진 데이터 준비"
      ],
      "metadata": {
        "id": "VHSytjlJ2z7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()  # 이전 인증 삭제\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ycPTcMnmc3B",
        "outputId": "fa3edcfa-d990-4c8e-cf88-d6090796782b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#구매한 아이템 이미지 파일 경로 리스트\n",
        "image_path = ['/content/drive/MyDrive/photo/jacket.webp','/content/drive/MyDrive/photo/trucker.webp']\n",
        "# 텍스트를 결합한 프롬프트\n",
        "text_prompts = [\n",
        "    \"Suggest pants that go well with these jacket.\"\n",
        "]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bS8oYZEFpTvR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [MYCODE] 이미지,텍스트 임베딩 처리"
      ],
      "metadata": {
        "id": "YuAyehCQe9A3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image_paths,text_prompt):\n",
        "    \"\"\"4\n",
        "    여러 이미지 경로를 입력으로 받아 처리. 단일 이미지도 리스트로 처리됨.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): 이미지 경로 리스트.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: 이미지 임베딩 텐서. 배치 형태로 반환.\n",
        "    \"\"\"\n",
        "    # 이미지 로드\n",
        "    images = [Image.open(path) for path in image_paths]\n",
        "\n",
        "    # 이미지 텍스트 전처리\n",
        "    inputs = clip_processor(text=text_prompts, images=images, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "    image_tensor = inputs[\"pixel_values\"]\n",
        "    #print(image_tensor.shape) # torch.Size([batch_size, num_channels, height, width])\n",
        "\n",
        "    outputs = clip_model(**inputs)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "Ah3cqMnG7ko6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.functional import cosine_similarity\n",
        "\n",
        "outputs = process_image(image_path,text_prompts)\n",
        "print(outputs.keys())\n",
        "\n",
        " # 이미지와 텍스트의 임베딩 추출\n",
        "image_embeds = outputs.image_embeds  # 이미지 임베딩\n",
        "text_embeds = outputs.text_embeds    # 텍스트 임베딩\n",
        "\n",
        "print(\"Image embedding shape:\", image_embeds.shape , image_embeds)\n",
        "print(\"Text embedding shape:\", text_embeds.shape, text_embeds)\n",
        "\n",
        "# 이미지들의 임베딩의 평균 계산\n",
        "combined_embedding = image_embeds.mean(dim=0)  # (3,)\n",
        "\n",
        "# 텍스트와의 유사도 계산\n",
        "similarity = cosine_similarity(combined_embedding.unsqueeze(0), text_embeds.unsqueeze(0), dim=1)\n",
        "print(\"결합된 임베딩 유사도:\", similarity)\n",
        "\n",
        "top_matches = torch.argsort(similarity, descending=True)\n",
        "\n",
        "# print(\"top_matches:\", top_matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXEJjz2juhxN",
        "outputId": "e04c8a7f-111f-4ce8-9c22-a070133e5653",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['logits_per_image', 'logits_per_text', 'text_embeds', 'image_embeds', 'text_model_output', 'vision_model_output'])\n",
            "Image embedding shape: torch.Size([2, 512]) tensor([[-0.0296,  0.0002,  0.0146,  ...,  0.0374,  0.0053,  0.0307],\n",
            "        [-0.0024,  0.0255,  0.0357,  ...,  0.0951,  0.0133,  0.0527]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Text embedding shape: torch.Size([1, 512]) tensor([[-2.8240e-03,  5.2022e-02, -6.9584e-03, -9.1824e-03, -1.2933e-02,\n",
            "         -4.4345e-03, -6.2870e-02, -2.2477e-02, -1.3359e-03, -2.3438e-02,\n",
            "         -3.5738e-03,  1.4213e-02, -1.3139e-02, -2.2988e-02,  2.2256e-02,\n",
            "          6.1014e-03,  2.8493e-02, -8.9735e-03,  1.5654e-02,  2.0316e-02,\n",
            "          9.3036e-03,  3.6925e-02,  4.7369e-03, -1.9623e-02,  4.2255e-02,\n",
            "          6.8918e-03, -2.4085e-02,  3.2735e-02, -1.1243e-02,  2.1658e-02,\n",
            "         -2.6321e-02, -6.5498e-03,  2.4495e-02,  1.0221e-02,  9.5645e-03,\n",
            "         -1.5969e-02,  9.3841e-03, -3.5463e-02, -1.1167e-02,  4.4552e-02,\n",
            "         -2.4406e-02, -1.4280e-02, -2.9949e-02,  2.7412e-02, -1.0948e-02,\n",
            "          1.3524e-02, -7.6769e-03,  1.0258e-02, -2.8757e-02,  1.8171e-02,\n",
            "          5.9469e-02, -3.6092e-02, -9.7398e-03, -2.0937e-02, -1.4513e-02,\n",
            "          2.5477e-02,  2.3407e-02, -1.9438e-02, -5.7529e-02, -9.1748e-03,\n",
            "          1.3826e-02,  3.6334e-02,  1.7031e-03, -1.2477e-02, -1.0839e-02,\n",
            "          8.1706e-03,  4.5248e-02,  9.3019e-03,  2.2094e-02,  2.4791e-03,\n",
            "          7.1888e-03, -1.5898e-02,  1.6149e-02,  2.2379e-02,  2.1853e-02,\n",
            "          9.2120e-03,  2.5696e-02,  3.8115e-02,  7.8096e-03, -8.6875e-03,\n",
            "         -4.4620e-02, -2.2834e-02, -1.5578e-02,  5.4456e-02, -7.3856e-04,\n",
            "          9.1112e-03,  1.3260e-02, -2.6464e-02, -7.8309e-03, -2.6113e-03,\n",
            "          7.9394e-04,  4.0523e-03, -1.1308e-01,  3.7374e-02, -2.0784e-02,\n",
            "         -3.0408e-02,  7.8193e-03, -2.5236e-02,  4.3146e-02,  4.5475e-02,\n",
            "          1.4633e-03, -1.5972e-03,  1.4518e-02, -1.0954e-03, -7.9958e-03,\n",
            "          4.5967e-02, -7.8281e-03, -6.5397e-03, -2.1167e-03, -4.0861e-02,\n",
            "         -3.5024e-02,  2.2612e-02,  2.8855e-02, -2.2276e-03, -2.7216e-02,\n",
            "         -3.8881e-04,  7.5109e-03,  4.3146e-02, -1.5363e-02,  3.8298e-02,\n",
            "          1.8182e-03, -4.2507e-02,  2.3311e-02, -1.7803e-02,  1.6980e-02,\n",
            "          7.6196e-03, -1.2815e-02, -2.2112e-03,  1.1121e-03,  1.3667e-02,\n",
            "          4.3867e-02,  7.3735e-03, -5.7417e-02,  5.5140e-01, -6.4838e-03,\n",
            "         -3.7562e-02, -2.4909e-03,  1.4709e-03,  4.6923e-03,  7.9392e-03,\n",
            "         -8.8505e-03,  3.2722e-02, -1.4882e-02,  2.7516e-02,  1.2329e-02,\n",
            "         -2.1010e-02, -9.1283e-03,  3.2538e-03, -9.4376e-03, -8.3790e-03,\n",
            "         -1.6835e-02,  5.6487e-03,  4.8402e-02,  3.4341e-02, -2.4816e-02,\n",
            "         -2.5256e-02,  1.5433e-03, -8.8759e-03, -4.8330e-02,  1.9708e-03,\n",
            "         -7.3144e-03, -1.4609e-02,  1.7675e-02,  1.3756e-02,  5.7407e-03,\n",
            "          1.4871e-03,  6.2028e-02, -2.2440e-02,  3.1894e-02,  5.4621e-03,\n",
            "         -4.0614e-03,  1.9423e-03,  2.5215e-02, -4.0397e-02, -4.2274e-02,\n",
            "         -1.3376e-02,  1.6889e-02, -3.3930e-03,  2.5201e-02,  1.2732e-03,\n",
            "          1.2391e-02, -1.6419e-03, -4.5530e-02,  1.2608e-02, -1.4859e-02,\n",
            "         -3.6385e-03, -1.6257e-03, -1.2368e-02,  1.7089e-02, -2.5088e-02,\n",
            "         -9.5712e-03,  4.2861e-02, -7.8872e-03,  4.0188e-03,  1.6168e-02,\n",
            "         -1.8090e-02,  1.8009e-02, -5.0692e-02, -5.3363e-03,  4.0878e-02,\n",
            "         -4.6922e-03,  1.7850e-02, -8.6889e-03, -8.2644e-03, -3.1529e-02,\n",
            "         -3.9943e-03,  5.4674e-02, -3.1664e-02, -6.0380e-03, -1.9780e-02,\n",
            "         -4.8369e-02,  5.2081e-04, -9.2765e-03, -2.7947e-02, -3.4885e-02,\n",
            "          6.1393e-03,  2.8307e-02,  2.1334e-02, -2.1616e-03, -3.3065e-02,\n",
            "          3.6619e-02, -4.8197e-02, -1.8348e-02,  8.4840e-03, -7.4644e-03,\n",
            "          2.8393e-02,  2.0921e-02,  3.4963e-02,  3.7215e-03, -5.8067e-02,\n",
            "          3.4115e-03, -1.3563e-02,  2.2640e-02, -1.1140e-02,  4.4563e-02,\n",
            "          3.8930e-02, -9.0198e-04,  9.9889e-03, -3.7270e-03,  1.8503e-03,\n",
            "          2.3414e-02, -5.4359e-03, -3.5997e-02,  1.0281e-02, -1.7813e-02,\n",
            "         -2.3294e-02,  3.3342e-02, -2.3692e-02,  9.1230e-03, -2.6519e-02,\n",
            "         -1.5655e-02, -1.0668e-02, -1.4381e-02,  7.6395e-03, -1.7608e-04,\n",
            "         -2.0975e-02,  8.0649e-04,  8.6917e-03, -1.9724e-02,  1.4651e-02,\n",
            "         -2.8493e-02, -1.0821e-03, -5.2818e-03, -3.6235e-02,  1.0016e-02,\n",
            "         -2.1490e-02,  5.1739e-03,  9.0498e-03, -2.4306e-02,  2.1601e-02,\n",
            "         -7.5448e-03,  3.8427e-02,  6.0607e-02, -2.6729e-02, -3.2976e-02,\n",
            "         -1.1827e-02, -1.9492e-02,  3.6424e-02, -9.9613e-03, -9.1283e-03,\n",
            "          1.2557e-03,  1.0409e-02,  1.5693e-02,  2.3355e-02,  4.1405e-03,\n",
            "         -6.9430e-03,  2.5166e-03,  1.6246e-02,  3.6597e-03,  4.1523e-02,\n",
            "          4.0101e-02,  1.7931e-02,  1.1880e-02,  1.6909e-02, -2.7941e-02,\n",
            "         -3.2383e-02, -6.3583e-02,  3.3532e-02, -2.2448e-02,  1.1416e-02,\n",
            "         -5.3814e-03,  3.3938e-03,  3.8564e-02,  1.4094e-02, -2.0865e-02,\n",
            "         -4.8324e-02, -2.3800e-02, -4.0504e-02, -7.3098e-03,  1.3948e-02,\n",
            "         -5.5764e-02,  3.4760e-02,  5.5109e-01,  4.7661e-02,  5.5909e-02,\n",
            "         -7.0182e-03,  2.5033e-04,  2.4724e-02, -3.4036e-02,  2.8695e-02,\n",
            "          2.6367e-03,  3.2564e-03,  6.0264e-02, -1.8415e-02, -9.3371e-03,\n",
            "         -3.3559e-03,  1.7389e-02,  1.8926e-02, -7.1706e-03, -1.2413e-01,\n",
            "         -7.4217e-03, -2.7383e-02,  2.9189e-02, -1.1719e-02,  4.3132e-02,\n",
            "         -6.0921e-02,  2.7282e-02, -8.0474e-03,  3.2017e-03,  3.1247e-02,\n",
            "         -3.5005e-02,  2.2367e-02,  2.1747e-03, -1.3860e-02,  6.5028e-03,\n",
            "         -1.2936e-02, -1.4087e-02,  5.7917e-02, -2.1092e-02, -2.5685e-02,\n",
            "          4.5066e-03, -4.5906e-02, -4.6014e-02,  1.1861e-02, -1.7877e-02,\n",
            "         -2.1702e-04,  2.4718e-02, -2.1070e-02, -2.3378e-02, -4.7552e-02,\n",
            "          3.2387e-02, -3.9439e-03, -3.7671e-02,  4.7300e-02,  7.4812e-02,\n",
            "         -1.3413e-02, -5.4286e-02,  1.4462e-02, -2.5992e-02,  1.1174e-02,\n",
            "         -2.4204e-02, -3.9189e-02,  1.6163e-02,  4.3443e-02,  3.1459e-02,\n",
            "         -5.3860e-02,  1.2536e-02, -9.3567e-03,  1.9750e-02, -5.1998e-02,\n",
            "          2.9221e-02,  2.5738e-03, -1.5977e-02, -5.7121e-02,  1.6728e-02,\n",
            "          2.6195e-02, -9.3057e-03,  1.3839e-03, -1.1999e-02,  2.1924e-02,\n",
            "         -7.6062e-02, -8.8773e-03, -1.9523e-02,  1.2262e-02, -3.3687e-02,\n",
            "         -3.7457e-03, -3.4297e-02,  7.4739e-03, -2.0493e-02,  2.5386e-02,\n",
            "          1.2753e-02,  1.9606e-02,  3.3713e-02,  2.6684e-02,  4.1025e-02,\n",
            "         -8.5866e-03, -1.2701e-03,  2.9658e-03, -4.7587e-02, -9.4406e-03,\n",
            "         -5.0855e-02, -8.2835e-03,  4.7934e-02,  5.7673e-04, -3.0946e-02,\n",
            "         -3.3332e-02,  3.3473e-02, -1.4749e-02, -2.1699e-02,  1.1552e-02,\n",
            "          1.0355e-02, -1.1800e-02,  2.8040e-02, -7.0799e-02, -1.9948e-02,\n",
            "         -4.3002e-02,  1.0359e-03,  2.8686e-02, -1.7115e-02,  8.2629e-03,\n",
            "         -5.7060e-02,  1.2564e-02,  1.1041e-03, -1.1651e-02, -1.8370e-02,\n",
            "          3.2591e-03, -4.7627e-02, -1.1267e-02,  7.8127e-03, -1.9200e-02,\n",
            "         -1.4013e-02,  4.1801e-02, -5.1509e-03, -6.7897e-03, -1.8159e-02,\n",
            "          8.1150e-05, -4.5571e-02, -1.1807e-03,  8.4954e-03, -2.1826e-02,\n",
            "         -4.7756e-02,  4.4340e-02, -2.5754e-03, -8.2289e-03,  1.7431e-02,\n",
            "          2.7721e-02,  4.5997e-03,  3.6278e-02, -5.7804e-03,  1.3288e-02,\n",
            "          3.1989e-02, -1.1650e-02, -4.8326e-02, -2.7428e-02,  2.7640e-02,\n",
            "         -2.1398e-02, -2.3475e-02,  2.5300e-03,  1.9835e-02, -3.4609e-03,\n",
            "          5.6529e-04, -1.4650e-03,  3.0150e-02,  1.8985e-02, -1.9969e-02,\n",
            "         -1.6961e-02, -5.5710e-03, -1.1815e-02,  6.8658e-03,  5.7245e-02,\n",
            "         -6.3912e-03, -5.9401e-02, -1.1072e-02, -5.6891e-04, -1.8236e-02,\n",
            "          1.8368e-02, -1.8109e-03, -1.4798e-02, -2.3471e-03, -6.3948e-02,\n",
            "          3.9626e-02, -1.2283e-03,  3.1863e-02,  1.2321e-01, -6.9696e-03,\n",
            "         -1.7329e-02,  3.8778e-02,  3.0521e-02,  9.3702e-03, -5.1980e-03,\n",
            "          3.0930e-02,  2.2791e-02, -3.3416e-03,  3.4946e-02,  5.5049e-02,\n",
            "         -2.9118e-02, -5.6178e-02,  1.4839e-02,  7.1389e-03, -5.7685e-02,\n",
            "          3.3753e-02,  2.7601e-02]], grad_fn=<DivBackward0>)\n",
            "결합된 임베딩 유사도: tensor([[ 1.,  1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1.,\n",
            "          1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
            "          1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,\n",
            "          1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
            "          1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
            "         -1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,\n",
            "         -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1.,\n",
            "          1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
            "         -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "          1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,\n",
            "         -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
            "          1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
            "          1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
            "         -1., -1., -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
            "          1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,\n",
            "          1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
            "         -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,\n",
            "          1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,\n",
            "         -1., -1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,\n",
            "         -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
            "          1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
            "          1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,\n",
            "         -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
            "         -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
            "          1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,\n",
            "         -1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
            "          1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
            "          1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
            "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
            "          1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,\n",
            "          1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
            "         -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,\n",
            "         -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,\n",
            "          1.,  1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,\n",
            "         -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
            "          1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
            "          1.,  1.,  1.,  1.,  1., -1.,  1.,  1.]], grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [MYCODE] GPT 모델에 입력할 prompt 생성\n",
        "> 유사도 계산하여 점수가 제일 높은 이미지를 선택하게 되있으나 input 이미지가 2개뿐으로 전체 를 넣어주는걸로 진행"
      ],
      "metadata": {
        "id": "HJtkcpNtO1pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 프롬프트에 이미지 임베딩을 넣어준다\n",
        "embedding_text = ', '.join([str(x) for x in image_embeds])\n",
        "#print(\"image_embedding_text : \", embedding_text)\n",
        "# 텍스트 임베딩을 문자열로 변환 (이 방법은 실제로 매우 단순화된 형태입니다)\n",
        "text_prompt = f\"Given the image embedding: {embedding_text},\\nPlease recommend some pants that would match the jacket photo.\"\n",
        "print(text_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kxCsrtj4O0C7",
        "outputId": "96716eef-4257-4bc0-caa3-934608500ccb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given the image embedding: tensor([-2.9559e-02,  2.3442e-04,  1.4630e-02,  1.8316e-03, -5.0913e-03,\n",
            "         6.5859e-03, -5.8771e-02,  1.5978e-02,  2.9565e-02,  2.2867e-02,\n",
            "        -5.2097e-03,  2.0580e-03, -1.8769e-02,  3.3024e-03,  2.7587e-02,\n",
            "        -2.2074e-02, -3.1574e-02,  6.0606e-03, -1.1207e-02, -2.2085e-03,\n",
            "        -1.5251e-02,  1.1632e-02,  3.6212e-02, -4.5900e-02,  3.3719e-02,\n",
            "         1.5531e-02,  8.9285e-03,  1.0745e-02,  3.1603e-03, -1.3570e-02,\n",
            "         3.7793e-02, -1.6377e-02, -2.7728e-02,  9.1010e-04,  2.5790e-02,\n",
            "         3.9760e-02,  3.6465e-03,  5.3960e-02,  8.1518e-03,  1.7742e-01,\n",
            "        -2.5719e-02,  1.0741e-02, -4.1633e-04,  2.5294e-02,  1.7934e-03,\n",
            "        -7.8408e-02,  2.6420e-02,  2.5408e-02,  1.6493e-02, -2.2836e-03,\n",
            "         9.2802e-02, -2.8382e-02,  1.5447e-02,  4.6112e-03, -4.5208e-02,\n",
            "         1.9615e-02,  3.1397e-02,  1.4522e-02, -1.6510e-02,  1.6095e-02,\n",
            "         1.2772e-02,  1.5448e-02,  4.8830e-02, -7.5552e-03, -5.5758e-02,\n",
            "        -2.8686e-03, -5.8583e-03, -3.9146e-02,  5.7103e-03,  1.3302e-02,\n",
            "        -1.5968e-02,  1.1225e-02, -2.3422e-02,  2.8181e-02, -8.5525e-03,\n",
            "         3.2895e-03,  3.6907e-02, -4.0963e-03,  1.4539e-02,  1.9058e-02,\n",
            "        -1.8243e-02, -5.1992e-02, -1.9792e-02, -4.7205e-03,  1.8456e-02,\n",
            "         3.7609e-03,  1.0734e-01, -3.5517e-02, -2.0554e-02, -1.8739e-02,\n",
            "         2.6904e-02,  2.5884e-02, -6.0019e-01,  1.6294e-02, -5.3135e-03,\n",
            "         2.0957e-02,  1.7780e-02,  1.2558e-02,  4.2437e-02,  1.3445e-01,\n",
            "        -2.7058e-02, -4.1683e-02,  2.8771e-02, -9.1362e-03, -5.4794e-02,\n",
            "         1.8263e-03, -8.4828e-02, -2.8176e-02, -2.0143e-03,  1.8939e-02,\n",
            "        -1.6734e-02,  2.8443e-02, -2.7835e-02,  2.3018e-02, -5.4822e-03,\n",
            "        -5.2540e-03, -1.6877e-02,  3.0301e-03,  3.5525e-03,  2.6131e-03,\n",
            "         1.6971e-02,  2.0357e-02,  7.0719e-03,  8.7127e-03, -2.3641e-02,\n",
            "        -5.5712e-03, -3.9671e-02,  3.0959e-02,  3.2115e-02,  2.3498e-02,\n",
            "         3.4509e-02, -6.6749e-04,  2.2268e-02,  7.0389e-02,  2.0289e-02,\n",
            "         1.9078e-04, -2.7558e-02,  4.8847e-02, -3.0322e-02,  4.3155e-02,\n",
            "         1.4658e-03, -4.0845e-02, -4.1546e-02,  3.7400e-02,  5.0294e-03,\n",
            "        -3.2540e-02,  1.0601e-02,  5.3708e-02,  2.4875e-02, -8.3801e-03,\n",
            "        -3.8250e-02,  2.7865e-02,  1.6443e-01,  3.1883e-02, -1.7334e-03,\n",
            "        -6.0093e-03,  8.5042e-03,  3.6109e-02, -1.2622e-02,  7.6308e-02,\n",
            "         7.9058e-03, -1.2652e-02,  4.6366e-02,  3.0350e-02,  2.3909e-02,\n",
            "        -3.5683e-03,  5.2253e-02,  6.8269e-03, -2.2704e-04, -5.3712e-03,\n",
            "        -2.6113e-02,  5.9605e-04,  1.1541e-02, -1.9319e-02, -5.0035e-02,\n",
            "        -4.5540e-02,  8.1243e-02,  1.4752e-02,  8.8532e-03, -4.3632e-02,\n",
            "         7.0933e-02,  3.0652e-02,  6.7273e-02, -2.2146e-02, -1.3638e-02,\n",
            "        -3.1542e-03, -1.2592e-02, -4.2249e-02,  5.8959e-03, -1.2104e-02,\n",
            "         2.6476e-02, -1.1547e-03, -1.1317e-03,  1.2549e-03,  6.6889e-02,\n",
            "        -1.0465e-02,  1.5038e-02, -8.7734e-03, -3.1346e-02,  3.9791e-02,\n",
            "        -3.0156e-02,  6.1940e-03,  1.8711e-02,  8.3310e-03,  5.0380e-03,\n",
            "        -1.3632e-02, -2.0157e-02, -2.0928e-02, -1.4653e-04,  4.8882e-02,\n",
            "        -7.6199e-02,  4.3466e-02, -1.5433e-02, -1.9277e-02, -9.4761e-02,\n",
            "        -5.6739e-03, -1.0024e-02,  4.0917e-02,  1.7432e-02, -3.0589e-02,\n",
            "        -4.1741e-02, -4.4286e-02, -2.3309e-03, -1.3960e-03,  2.7453e-02,\n",
            "         1.7661e-02,  1.3392e-02, -2.3671e-02, -2.0764e-02,  1.8763e-02,\n",
            "        -1.3407e-02, -4.3842e-02,  3.4596e-03,  6.4739e-02,  2.1245e-02,\n",
            "        -8.7386e-03,  3.7160e-02, -3.1117e-02, -1.9386e-02, -5.5582e-03,\n",
            "        -8.6817e-03,  3.4695e-02,  3.1471e-02, -1.8570e-02, -1.1848e-02,\n",
            "        -2.4324e-02, -2.4728e-02, -1.1364e-02,  5.5204e-03, -1.8254e-02,\n",
            "         1.5500e-02, -1.2716e-02,  3.2660e-02, -2.1326e-02,  1.6119e-02,\n",
            "         2.7373e-02,  6.0224e-03,  5.5950e-02, -1.5671e-01, -2.5817e-02,\n",
            "         1.5150e-02,  1.2376e-02, -1.2416e-02, -2.8522e-02, -2.0793e-02,\n",
            "        -3.3090e-02, -6.7076e-03,  1.5005e-02, -1.1979e-02, -3.4748e-03,\n",
            "         2.4007e-03,  2.0742e-02,  2.4355e-02, -3.6069e-02, -1.0103e-02,\n",
            "        -1.7633e-02, -3.2319e-02,  5.4442e-03, -3.1896e-02,  1.3201e-02,\n",
            "         1.3262e-02, -4.7387e-03, -5.1614e-02,  4.9394e-03,  1.1122e-02,\n",
            "         1.1455e-02,  1.1305e-01, -1.6795e-03,  1.1240e-02,  2.3761e-02,\n",
            "        -3.2273e-03, -1.2814e-02, -8.4682e-03, -5.2779e-03, -4.0366e-02,\n",
            "         9.2970e-03, -4.7448e-02,  1.8152e-02,  6.4005e-03,  2.1372e-02,\n",
            "        -1.1078e-02, -1.8906e-02,  1.3792e-02,  7.1045e-04, -9.3003e-03,\n",
            "        -9.3515e-02, -1.5212e-02,  2.4605e-02,  1.5066e-02, -2.4291e-03,\n",
            "        -5.2133e-02,  7.3609e-03,  7.0289e-02, -2.0462e-02, -9.2841e-03,\n",
            "        -8.6888e-03,  2.4398e-02,  3.1962e-02, -1.5125e-02, -2.0318e-02,\n",
            "         1.9518e-02,  1.7543e-01, -5.1797e-03, -3.3150e-02,  2.9555e-02,\n",
            "         3.8683e-03,  3.5474e-02,  2.7115e-02, -3.2070e-04, -3.1998e-02,\n",
            "         1.1495e-03, -1.1493e-02, -9.3723e-03, -3.3090e-02,  9.7657e-03,\n",
            "         1.7182e-02,  2.4919e-02, -3.1784e-02, -2.7039e-02, -3.3102e-02,\n",
            "        -1.5077e-02, -2.4578e-02,  5.1475e-04, -1.0545e-02, -4.6765e-03,\n",
            "        -2.8632e-02, -4.1970e-02, -2.8069e-02,  1.3199e-03, -2.2920e-03,\n",
            "        -2.4345e-02,  4.7983e-03, -1.3995e-02, -4.7412e-02, -1.2833e-02,\n",
            "         7.3528e-02, -2.7491e-02, -1.6611e-02,  1.2789e-03, -4.1093e-02,\n",
            "         7.8231e-02, -9.7743e-03, -4.8376e-02,  1.8650e-02,  9.4715e-02,\n",
            "        -1.9882e-02, -7.3695e-04,  1.7302e-02,  9.4037e-04, -1.8208e-02,\n",
            "         7.3913e-03, -9.4607e-03,  3.5887e-03,  3.8620e-02,  4.8492e-02,\n",
            "        -3.4649e-02,  4.8220e-02,  5.4873e-03,  5.5186e-03,  1.4900e-02,\n",
            "        -1.6869e-02, -2.4075e-03, -1.5809e-02, -8.5038e-03, -1.2824e-02,\n",
            "        -4.9497e-03, -1.6731e-02,  1.7902e-02, -6.3051e-03,  8.7844e-02,\n",
            "        -1.0196e-01, -4.5568e-02, -4.8497e-02, -3.7923e-03, -3.4019e-02,\n",
            "        -1.3028e-02, -4.2524e-03,  1.8244e-02, -4.7490e-03,  6.7163e-02,\n",
            "         2.1141e-02,  1.3173e-02,  9.7228e-02, -3.4661e-02,  3.8229e-02,\n",
            "        -1.4916e-02, -4.9302e-03, -2.3873e-02,  1.4268e-02, -1.1190e-02,\n",
            "         2.3414e-02, -7.3269e-02, -4.6176e-03,  2.0246e-02, -6.2098e-02,\n",
            "         3.3434e-03,  9.0773e-02,  2.9596e-02, -1.8000e-02, -5.1434e-02,\n",
            "         2.3722e-02,  2.3922e-02,  1.9199e-02, -1.7959e-03, -3.3325e-02,\n",
            "         1.2796e-02,  2.9298e-02,  5.7563e-02, -1.3824e-01, -4.6154e-02,\n",
            "         8.3998e-03,  1.6107e-03,  1.6677e-01,  3.9132e-03,  1.1000e-02,\n",
            "        -1.1131e-02, -5.7726e-03,  1.4340e-02,  3.4971e-02,  8.6779e-03,\n",
            "        -2.5928e-02,  3.7813e-02, -4.2739e-03,  3.2822e-04,  3.4547e-03,\n",
            "        -4.3602e-02, -5.0187e-02,  2.0523e-03, -1.9040e-02,  2.6582e-02,\n",
            "        -4.2363e-02,  8.7750e-03,  3.9318e-02,  1.9474e-03, -2.3497e-02,\n",
            "         2.9359e-02,  5.8276e-03,  2.1066e-02,  6.3976e-04,  1.3540e-02,\n",
            "         1.9805e-02,  3.9693e-03, -8.5292e-03, -2.1721e-02,  1.3502e-03,\n",
            "         2.0779e-03,  2.4552e-03,  1.5934e-02, -2.4124e-03,  2.3583e-02,\n",
            "        -1.7055e-02, -1.4950e-03,  2.8794e-02, -4.3203e-02,  2.3686e-02,\n",
            "        -2.1618e-02,  1.0991e-02,  9.5506e-03,  1.1125e-02,  1.4275e-02,\n",
            "        -1.4687e-04, -3.9455e-02,  2.9539e-03,  9.4302e-03,  2.3463e-02,\n",
            "         1.9848e-02, -3.6613e-02,  3.0117e-03, -2.8392e-02, -3.8359e-02,\n",
            "         1.5242e-02, -1.3853e-02,  4.1293e-02, -2.7462e-02, -6.5646e-02,\n",
            "        -2.7319e-02,  5.5541e-02,  8.2939e-03, -1.2997e-03,  1.8515e-02,\n",
            "        -3.6449e-02,  1.5210e-02, -2.5792e-02,  9.8331e-04,  7.5079e-02,\n",
            "        -2.0633e-02, -3.8411e-02,  1.2882e-02,  1.5426e-02,  3.7364e-02,\n",
            "         5.2978e-03,  3.0731e-02], grad_fn=<UnbindBackward0>), tensor([-2.4054e-03,  2.5481e-02,  3.5709e-02,  3.0087e-03, -5.4261e-03,\n",
            "        -3.0071e-03, -6.0433e-02,  1.3576e-02,  2.7378e-02, -5.5397e-03,\n",
            "         2.6529e-02,  2.0883e-02,  4.0453e-02,  1.5389e-02,  1.7479e-02,\n",
            "        -1.6708e-02,  6.8246e-02,  1.0197e-02,  2.2228e-02, -2.6722e-03,\n",
            "         1.7055e-02,  3.9300e-02,  3.4074e-02, -3.4580e-02,  2.8762e-03,\n",
            "         3.2617e-02, -3.7511e-02, -4.6462e-02, -1.1315e-02, -3.1737e-02,\n",
            "         1.0946e-03, -1.4797e-02,  5.2604e-03,  1.9894e-02,  5.4454e-03,\n",
            "         1.8951e-02, -1.1943e-02,  2.4870e-03, -9.3075e-03,  1.6954e-01,\n",
            "        -2.8633e-02, -1.5180e-02, -7.7489e-03, -1.2202e-03,  1.3866e-02,\n",
            "        -1.8153e-01,  2.3666e-02, -2.2963e-02,  1.0017e-02,  3.1184e-02,\n",
            "         6.2386e-02, -3.9698e-03,  3.1849e-02,  7.1048e-03, -4.4568e-02,\n",
            "         4.5089e-02,  2.5197e-02,  1.8611e-02, -2.6630e-02,  2.4588e-02,\n",
            "        -9.0463e-03,  1.8551e-02,  4.2356e-02,  1.9371e-03, -3.3144e-02,\n",
            "        -9.8220e-03,  1.8058e-02, -3.3287e-02,  8.4210e-03,  2.3902e-02,\n",
            "        -3.0652e-02,  4.5820e-02,  2.7863e-03,  1.6212e-02,  4.4570e-04,\n",
            "        -1.5762e-03,  3.0846e-02, -2.5361e-02,  4.8199e-02,  5.5263e-03,\n",
            "        -3.8069e-02, -3.4143e-02, -4.1364e-02,  4.6593e-03,  1.0298e-02,\n",
            "         1.1459e-02,  7.5275e-02, -6.8096e-02,  6.3277e-03, -3.0341e-02,\n",
            "         4.4974e-02,  7.0687e-03, -5.9520e-01,  3.6574e-02,  3.8594e-02,\n",
            "         9.9000e-03,  1.8813e-02,  1.5540e-03,  1.7750e-02,  8.0650e-02,\n",
            "        -1.3845e-02, -6.2569e-02,  3.4168e-02, -2.3562e-02, -3.7305e-02,\n",
            "         2.6328e-02, -7.4117e-02, -3.4605e-04, -1.1817e-02,  7.8667e-03,\n",
            "         1.2555e-02,  2.3401e-02, -1.6186e-02,  2.5361e-03,  6.9662e-03,\n",
            "        -1.0535e-02, -3.3665e-02, -2.3837e-02,  2.3492e-02, -1.0285e-02,\n",
            "        -2.1097e-02,  3.9692e-02, -3.7836e-02,  9.1220e-03, -3.7665e-02,\n",
            "         5.3561e-03, -4.7369e-02,  1.7566e-02,  2.0878e-02,  1.3993e-02,\n",
            "         3.4772e-02,  4.2051e-03,  3.7927e-03,  6.8024e-02,  5.6286e-02,\n",
            "         5.9075e-03,  1.2427e-02,  5.2683e-02, -1.2670e-02,  2.8068e-03,\n",
            "         1.1824e-02, -2.3338e-02, -4.2275e-02,  1.4876e-02,  3.9805e-04,\n",
            "        -1.2078e-02, -7.0389e-03,  2.4081e-02,  2.5066e-03, -1.3584e-02,\n",
            "        -1.4058e-03,  3.4597e-02,  1.4625e-01,  3.1922e-02, -1.9265e-02,\n",
            "        -1.4876e-02,  5.7360e-03,  8.8516e-02, -4.1175e-03,  1.5208e-02,\n",
            "        -4.1754e-02, -3.1195e-02,  1.5908e-02,  5.0429e-02, -1.2821e-02,\n",
            "        -1.9653e-02,  4.6408e-02,  8.7219e-03,  1.2028e-02, -5.7456e-03,\n",
            "        -1.9160e-02, -9.2481e-03,  1.1669e-02, -2.6028e-02, -2.6335e-02,\n",
            "        -3.1782e-02,  1.1513e-01,  2.7168e-04, -1.0308e-02, -2.3470e-02,\n",
            "         7.2082e-02,  1.2007e-02,  3.2312e-02,  1.1502e-03,  1.8538e-02,\n",
            "         1.7426e-02,  7.5364e-03, -2.7452e-02, -3.5354e-02, -3.8897e-02,\n",
            "         1.7673e-02,  2.1684e-02,  3.8933e-03,  3.8153e-03,  4.9035e-02,\n",
            "        -7.1208e-03,  2.1634e-02, -5.5640e-03, -3.3262e-02,  1.8300e-02,\n",
            "        -3.0373e-02, -3.1420e-02, -7.1298e-03, -4.5737e-03, -2.6427e-02,\n",
            "         8.6449e-03, -3.7993e-02, -5.3704e-02, -1.2261e-02,  4.8212e-02,\n",
            "        -4.9739e-02,  3.3747e-02, -3.4048e-03, -1.2917e-02, -5.6529e-02,\n",
            "         8.4027e-03,  4.0651e-03,  4.4887e-02, -2.9542e-03, -2.2990e-02,\n",
            "        -2.4348e-02, -2.9336e-02, -4.6486e-04,  3.7954e-03,  1.4205e-02,\n",
            "         4.6066e-03,  2.1130e-02, -4.6695e-03,  5.2381e-03, -2.1397e-02,\n",
            "        -1.5759e-03, -3.4570e-02,  1.0459e-03,  5.0353e-02,  5.1952e-03,\n",
            "         4.0579e-02, -7.4673e-03, -1.7400e-02, -1.3040e-02,  2.1355e-02,\n",
            "         1.0681e-02,  1.5255e-02,  2.4751e-02, -4.3502e-02,  1.6559e-02,\n",
            "        -2.2029e-02, -1.2648e-02, -9.6110e-03, -2.3047e-02,  1.3194e-02,\n",
            "        -1.4620e-03,  2.2954e-02,  4.0151e-02,  7.8187e-03, -2.5290e-02,\n",
            "         2.3850e-02, -1.5589e-02,  4.0405e-02, -1.5545e-01, -2.7129e-02,\n",
            "         4.4809e-02,  8.0204e-03, -3.3901e-02, -5.6638e-02,  1.6833e-02,\n",
            "        -1.2365e-02, -2.2352e-03,  1.6112e-02, -5.0036e-03,  8.8228e-03,\n",
            "        -5.2252e-03,  4.9956e-02,  1.8541e-02, -2.5275e-02,  4.6933e-03,\n",
            "        -2.5739e-02, -1.8468e-02, -6.7027e-03, -6.0268e-02, -1.3578e-02,\n",
            "         1.0959e-02,  6.6447e-03, -5.2036e-02, -1.2986e-02,  1.2306e-02,\n",
            "         5.1288e-03,  1.5939e-01, -1.3863e-03, -4.6808e-02,  1.1452e-02,\n",
            "         2.7949e-02,  8.1445e-03, -3.3631e-02,  4.6061e-03, -1.2646e-02,\n",
            "         1.0475e-02, -2.7196e-02, -8.5237e-03, -1.2441e-03,  1.0485e-02,\n",
            "        -2.9409e-02, -9.4546e-03,  1.8248e-03, -1.6209e-02, -1.1740e-02,\n",
            "        -7.6554e-02, -1.6116e-02,  4.8485e-03,  9.5956e-03,  1.3999e-04,\n",
            "        -3.6156e-02,  4.5875e-03,  6.7797e-02,  6.1369e-04,  8.3790e-03,\n",
            "        -8.2910e-03,  1.3578e-02,  4.0588e-03, -2.3308e-02, -6.6991e-04,\n",
            "        -7.0488e-03,  1.8057e-01, -1.5430e-02, -6.1851e-02,  4.3455e-02,\n",
            "        -2.4538e-02,  6.1275e-02,  1.3186e-02, -1.9486e-02, -2.6120e-02,\n",
            "        -1.5033e-02,  1.1334e-02,  1.6385e-02, -1.9344e-02,  1.2411e-02,\n",
            "         1.9193e-02,  1.0303e-03, -7.1759e-03,  1.7025e-02, -1.4833e-02,\n",
            "        -2.7810e-02, -3.6980e-02,  7.9686e-03,  2.2384e-02,  1.5466e-02,\n",
            "        -1.9566e-02, -3.9720e-02, -4.6860e-02,  1.3031e-02, -5.0420e-03,\n",
            "        -1.7246e-02, -1.4054e-02,  4.5400e-03,  5.1394e-03, -7.6637e-03,\n",
            "         4.7726e-02, -5.1757e-02,  1.7589e-02,  3.1558e-03, -4.2007e-02,\n",
            "         6.7128e-02, -1.5284e-02, -3.2345e-02,  3.1889e-02,  8.2581e-02,\n",
            "        -2.6823e-02, -7.0389e-05,  4.6547e-02, -4.0865e-04, -2.3015e-02,\n",
            "         3.8950e-03, -2.1514e-02,  5.9594e-03,  2.7812e-02,  3.8034e-03,\n",
            "        -2.0894e-02,  7.0250e-02, -1.2961e-02,  2.2473e-02,  6.5014e-03,\n",
            "        -2.4499e-02, -3.6084e-02, -2.8502e-02, -1.5384e-02, -1.6440e-02,\n",
            "        -9.2443e-03,  8.3309e-03,  1.7960e-02,  1.2944e-03,  1.1470e-01,\n",
            "        -7.8580e-02, -2.1445e-02, -9.2694e-03,  1.3833e-02, -3.1825e-02,\n",
            "         7.5565e-03, -5.9853e-03,  3.5813e-03,  1.7040e-03,  4.0207e-02,\n",
            "         1.9767e-02,  2.3612e-02,  8.5989e-02, -3.0772e-02,  4.5448e-02,\n",
            "        -6.1231e-03, -5.2992e-04,  3.0848e-02,  2.6732e-02, -8.9902e-04,\n",
            "         2.3349e-02, -3.1164e-04,  1.2136e-02,  1.2518e-02, -5.4661e-02,\n",
            "         3.9298e-02,  3.2609e-02,  1.9674e-02, -3.4790e-02, -6.0311e-02,\n",
            "         3.1156e-02,  2.5873e-02,  4.4109e-02,  2.7100e-02, -2.8358e-02,\n",
            "         9.3306e-03,  1.7038e-02,  4.5774e-02, -1.8436e-01, -5.4028e-02,\n",
            "        -1.4159e-02,  3.1123e-02,  1.0465e-01, -1.2280e-02,  1.5684e-02,\n",
            "        -4.6062e-03, -1.0454e-02,  2.4039e-02,  5.8052e-02, -8.2301e-03,\n",
            "        -2.2190e-02,  6.1828e-03,  1.7034e-02,  5.2063e-03,  5.1028e-02,\n",
            "        -4.8155e-02, -2.5341e-02, -1.4434e-02, -3.2225e-03,  9.4763e-03,\n",
            "        -4.5514e-02,  4.8308e-03,  1.4862e-03, -5.9694e-02, -5.0482e-03,\n",
            "         8.5566e-03, -1.9679e-02,  2.3520e-02,  1.6608e-02, -1.2504e-02,\n",
            "        -9.0095e-03,  3.4777e-03, -6.3188e-03, -1.2038e-02,  7.9205e-03,\n",
            "         1.2329e-02, -1.7788e-03, -1.5998e-02, -1.7120e-02,  1.4896e-02,\n",
            "         8.8403e-03, -1.0614e-02,  3.9465e-02, -6.2188e-02, -6.3945e-03,\n",
            "        -4.1797e-02,  1.2109e-02,  2.4133e-02, -1.6807e-03,  3.9587e-02,\n",
            "        -1.9899e-02, -3.4214e-02,  1.0604e-02,  8.8874e-03,  2.0399e-02,\n",
            "         2.3526e-02, -4.1488e-02,  1.2273e-02, -4.1173e-03, -4.9689e-02,\n",
            "         2.7518e-02, -1.3839e-02,  1.7399e-02, -5.1794e-02, -5.7309e-02,\n",
            "        -3.2385e-02,  3.4754e-02,  1.7777e-02,  1.1304e-02,  3.7043e-03,\n",
            "        -2.8078e-02,  3.7879e-02, -2.4163e-02,  4.4246e-04,  3.3595e-02,\n",
            "        -2.3010e-02, -5.9328e-02,  2.0184e-03, -1.4407e-02,  9.5105e-02,\n",
            "         1.3273e-02,  5.2694e-02], grad_fn=<UnbindBackward0>),\n",
            "Please recommend some pants that would match the jacket photo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [MYCODE] 최종 결과"
      ],
      "metadata": {
        "id": "2lS_PherXPbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recommendations = generate_recommendation(text_prompt)\n",
        "print(recommendations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWL7LCqARCEk",
        "outputId": "5f67cca1-51a4-4e63-b4b5-90dee28ece38"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이 전자 사진의 이미지 임베딩을 고려했을 때, 다음과 같은 스타일의 바지를 추천합니다:\n",
            "\n",
            "1. **슬림 핏 팬츠**: 이미지 임베딩에서 추출된 정보가 모던하고 세련된 느낌을 준다면, 슬림 핏 팬츠가 잘 어울릴 것입니다. 간결하고 깔끔한 라인이 전체적인 룩의 일관성을 유지해 줄 것입니다.\n",
            "\n",
            "2. **네이비 또는 다크 컬러 팬츠**: 네이비 또는 짙은 색상의 바지는 다채로운 색상의 자켓과도 잘 어울리며, 고급스러운 느낌을 더해 줄 수 있습니다.\n",
            "\n",
            "3. **카키 또는 올리브 그린 팬츠**: 좀 더 캐주얼하면서도 트렌디한 느낌을 원한다면, 카키 또는 올리브 그린 색상의 팬츠도 고려해볼 만합니다.\n",
            "\n",
            "4. **청바지**: 자켓의 스타일에 따라 다르겠지만, 약간 캐주얼하면서도 멋스럽게 연출하고 싶다면 진한 색상의 슬림 핏 청바지도 좋은 선택이 될 수 있습니다.\n",
            "\n",
            "이 추천들은 제시된 이미지 임베딩을 기반으로 한 것이며, 최종적인 선택은 자켓의 구체적인 디자인과 사용자의 개인 스타일에 따라 달라질 수 있습니다.\n"
          ]
        }
      ]
    }
  ]
}